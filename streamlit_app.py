import streamlit as st
from gradio_client import Client, handle_file
import tempfile
import shutil
import os

# ---------- CONFIG ----------
st.set_page_config(page_title="Vimeo AI - Video Generator", page_icon="üé¨", layout="centered")
STATIC_DIR = "static"
os.makedirs(STATIC_DIR, exist_ok=True)

# ---------- CLIENTS ----------
video_client = Client("Lightricks/ltx-video-distilled")
tts_client = Client("MohamedRashad/Multilingual-TTS")

# ---------- ONGLETS ----------
tab1, tab2 = st.tabs(["üé• Video", "üó£ Transcript"])

# ---------- TAB VIDEO ----------
with tab1:
    uploaded_file = st.file_uploader("üì∑ Choisissez une image", type=["png", "jpg", "jpeg"])
    prompt = st.text_input("üìù Entrez une description / prompt pour la vid√©o")
    col1, col2 = st.columns([1, 1])
    with col1:
        duration = st.slider("‚è± Dur√©e de la vid√©o (sec)", 2, 10, 5)
    with col2:
        resolution = st.selectbox("üé• R√©solution", ["512x512", "704x512", "1024x576"])

# ---------- TAB TRANSCRIPT ----------
with tab2:
    transcript_text = st.text_area("üìù Entrez le texte que le mod√®le doit lire dans la vid√©o")
    transcript_language = st.selectbox("üåê Langue du texte", ["French", "English", "Spanish", "Arabic"])

# ---------- GENERATE BUTTON ----------
if st.button("üöÄ G√©n√©rer la vid√©o"):
    if uploaded_file is None:
        st.error("‚ö†Ô∏è Veuillez s√©lectionner une image.")
    elif not prompt:
        st.error("‚ö†Ô∏è Veuillez entrer une description pour la vid√©o.")
    else:
        try:
            # ---- TEMP IMAGE ----
            with tempfile.NamedTemporaryFile(delete=False, suffix=uploaded_file.name) as tmp_file:
                tmp_file.write(uploaded_file.read())
                temp_path = tmp_file.name

            # ---- VIDEO GENERATION ----
            width, height = map(int, resolution.split("x"))
            video_result, _ = video_client.predict(
                prompt=prompt,
                input_image_filepath=handle_file(temp_path),
                height_ui=height,
                width_ui=width,
                mode="image-to-video",
                duration_ui=duration,
                ui_frames_to_use=9,
                seed_ui=42,
                randomize_seed=True,
                ui_guidance_scale=1,
                improve_texture_flag=True,
                api_name="/image_to_video"
            )

            if not (isinstance(video_result, dict) and "video" in video_result):
                st.error(f"‚ùå Erreur vid√©o : {video_result}")
                st.stop()

            video_local_path = video_result["video"]
            st.success("‚úÖ Vid√©o g√©n√©r√©e avec succ√®s !")

            # ---- TTS GENERATION ----
            if transcript_text:
                speakers_data, _ = tts_client.predict(
                    language=transcript_language,
                    api_name="/get_speakers"
                )
                speaker = speakers_data["value"]

                _, audio_path = tts_client.predict(
                    text=transcript_text,
                    language_code=transcript_language,
                    speaker=speaker,
                    tashkeel_checkbox=False,
                    api_name="/text_to_speech_edge"
                )

                st.success("üé§ Audio g√©n√©r√© avec succ√®s !")

                # ---- AFFICHAGE SIMULTAN√â ----
                col_video, col_audio = st.columns([1, 1])
                with col_video:
                    st.video(video_local_path)
                with col_audio:
                    st.audio(audio_path)

            else:
                st.video(video_local_path)

        except Exception as e:
            st.error(f"üö® Erreur lors de la g√©n√©ration : {str(e)}")
