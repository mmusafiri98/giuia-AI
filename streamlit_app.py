import streamlit as st
import tempfile
import os
import numpy as np
from PIL import Image
import warnings
warnings.filterwarnings("ignore")

# ---------- CONFIG INTERFACE ----------
st.set_page_config(
    page_title="Vimeo AI - Video Generator",
    page_icon="üé¨",
    layout="centered"
)

# ---------- CSS custom ----------
st.markdown("""
    <style>
    body {
        background-color: #ffffff;
        color: #000000;
    }
    .stApp {
        background-color: #ffffff;
        color: #000000;
    }
    .app-header {
        background-color: #f5f9ff;
        padding: 15px;
        text-align: left;
        font-size: 22px;
        font-weight: bold;
        color: #000000;
        border-bottom: 2px solid #dcecff;
    }
    .brand {
        color: #1ab7ea;
    }
    .stTextInput, .stFileUploader, .stTextArea {
        background-color: #f5faff;
        color: #000000;
        border-radius: 8px;
        border: 1px solid #d0e7f7;
    }
    .stButton>button {
        background-color: #1ab7ea;
        color: white;
        font-weight: bold;
        border-radius: 8px;
        height: 50px;
        width: 100%;
        border: none;
    }
    .stButton>button:hover {
        background-color: #18a5d5;
        color: white;
    }
    .error-box {
        background-color: #ffe6e6;
        padding: 15px;
        border-radius: 5px;
        border-left: 4px solid #ff4444;
        margin: 10px 0;
    }
    .info-box {
        background-color: #e8f4fd;
        padding: 15px;
        border-radius: 5px;
        border-left: 4px solid #1ab7ea;
        margin: 10px 0;
    }
    </style>
""", unsafe_allow_html=True)

# ---------- HEADER ----------
st.markdown("<div class='app-header'><span class='brand'>Vimeo AI</span> - Video Generator</div>", unsafe_allow_html=True)

# ---------- CHECK DEPENDENCIES ----------
def check_dependencies():
    """V√©rifie si toutes les d√©pendances sont install√©es"""
    missing = []
    
    try:
        import torch
    except ImportError:
        missing.append("torch")
    
    try:
        import cv2
    except ImportError:
        missing.append("opencv-python")
    
    try:
        from diffusers import DiffusionPipeline
    except ImportError:
        missing.append("diffusers")
    
    try:
        from transformers import pipeline
    except ImportError:
        missing.append("transformers")
    
    return missing

# V√©rification des d√©pendances
missing_deps = check_dependencies()

if missing_deps:
    st.markdown("""
    <div class='error-box'>
    ‚ùå <strong>D√©pendances manquantes d√©tect√©es :</strong><br>
    """ + ", ".join(missing_deps) + """
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class='info-box'>
    üì¶ <strong>Pour corriger le probl√®me :</strong><br><br>
    
    <strong>Option 1 - Installation locale :</strong><br>
    <code>pip install torch diffusers transformers opencv-python pillow</code><br><br>
    
    <strong>Option 2 - Streamlit Cloud :</strong><br>
    Cr√©ez un fichier <code>requirements.txt</code> avec :<br>
    <pre>streamlit
torch
diffusers
transformers
opencv-python-headless
pillow
numpy
huggingface-hub</pre><br>
    
    <strong>Option 3 - Version CPU uniquement :</strong><br>
    <code>pip install torch --index-url https://download.pytorch.org/whl/cpu</code>
    </div>
    """, unsafe_allow_html=True)
    
    # Interface limit√©e en mode d√©grad√©
    st.warning("‚ö†Ô∏è Application en mode d√©grad√© - Fonctionnalit√©s limit√©es")
    
    uploaded_file = st.file_uploader("üì∑ Image (non fonctionnel sans d√©pendances)", type=["png", "jpg", "jpeg"], disabled=True)
    prompt = st.text_input("üìù Prompt (non fonctionnel sans d√©pendances)", disabled=True)
    
    if st.button("üöÄ Installer les d√©pendances d'abord", disabled=True):
        st.error("Veuillez installer les d√©pendances PyTorch d'abord")
    
    st.stop()

# Import des d√©pendances (apr√®s v√©rification)
import torch
import cv2
from diffusers import DiffusionPipeline
from transformers import pipeline

# ---------- CONFIGURATION ----------
STATIC_DIR = "static"
os.makedirs(STATIC_DIR, exist_ok=True)

@st.cache_resource
def load_model():
    """Charge le mod√®le avec gestion d'erreurs robuste"""
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        dtype = torch.float16 if device == "cuda" else torch.float32
        
        st.info(f"üîÑ Chargement du mod√®le sur {device.upper()}...")
        
        # Essai mod√®le principal
        try:
            pipe = DiffusionPipeline.from_pretrained(
                "Lightricks/ltx-video",
                torch_dtype=dtype,
                low_cpu_mem_usage=True,
                device_map="auto" if device == "cuda" else None
            )
            model_name = "LTX-Video"
        except Exception as e:
            st.warning(f"LTX-Video indisponible: {str(e)}")
            
            # Mod√®le de fallback
            try:
                pipe = DiffusionPipeline.from_pretrained(
                    "ali-vilab/text-to-video-ms-1.7b",
                    torch_dtype=dtype,
                    low_cpu_mem_usage=True
                )
                model_name = "Text-to-Video MS"
            except Exception as e2:
                st.error(f"Tous les mod√®les ont √©chou√©: {str(e2)}")
                return None, None, device
        
        pipe = pipe.to(device)
        
        # Optimisations
        if hasattr(pipe, 'enable_memory_efficient_attention'):
            pipe.enable_memory_efficient_attention()
        if hasattr(pipe, 'enable_vae_slicing'):
            pipe.enable_vae_slicing()
            
        return pipe, model_name, device
        
    except Exception as e:
        st.error(f"‚ùå Erreur critique : {str(e)}")
        return None, None, "cpu"

# ---------- FONCTIONS UTILITAIRES ----------
def preprocess_image(image, target_size=(512, 512)):
    """Pr√©processe l'image"""
    if isinstance(image, Image.Image):
        image = image.convert("RGB")
        image = image.resize(target_size, Image.Resampling.LANCZOS)
        return image
    return None

def generate_frames(pipe, prompt, image=None, num_frames=16, width=512, height=512, device="cpu"):
    """G√©n√®re les frames vid√©o"""
    try:
        if device == "cuda":
            torch.cuda.empty_cache()
        
        with torch.no_grad():
            if image is not None:
                result = pipe(
                    prompt=prompt,
                    image=image,
                    num_frames=num_frames,
                    height=height,
                    width=width,
                    num_inference_steps=20,  # R√©duit pour la vitesse
                    guidance_scale=7.5
                )
            else:
                result = pipe(
                    prompt=prompt,
                    num_frames=num_frames,
                    height=height,
                    width=width,
                    num_inference_steps=20,
                    guidance_scale=7.5
                )
        
        if hasattr(result, 'frames'):
            return result.frames[0]
        elif hasattr(result, 'videos'):
            return result.videos[0]
        return None
        
    except Exception as e:
        st.error(f"Erreur g√©n√©ration: {str(e)}")
        return None

def create_video(frames, output_path, fps=8):
    """Cr√©e une vid√©o √† partir des frames"""
    if not frames:
        return False
    
    try:
        frame_arrays = []
        for frame in frames:
            if isinstance(frame, Image.Image):
                frame_arrays.append(np.array(frame))
        
        if not frame_arrays:
            return False
        
        height, width = frame_arrays[0].shape[:2]
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        for frame_array in frame_arrays:
            if len(frame_array.shape) == 3:
                frame_bgr = cv2.cvtColor(frame_array, cv2.COLOR_RGB2BGR)
            else:
                frame_bgr = frame_array
            out.write(frame_bgr)
        
        out.release()
        return True
        
    except Exception as e:
        st.error(f"Erreur vid√©o: {str(e)}")
        return False

# ---------- CHARGEMENT MOD√àLE ----------
with st.spinner("Initialisation du mod√®le..."):
    pipe, model_name, device = load_model()

if pipe is None:
    st.error("‚ùå Impossible de charger un mod√®le de g√©n√©ration vid√©o")
    st.info("üí° V√©rifiez votre connexion internet et r√©essayez")
    st.stop()

# ---------- INFO MOD√àLE ----------
st.success(f"‚úÖ Mod√®le charg√©: **{model_name}** sur **{device.upper()}**")

if device == "cuda":
    gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**3)
    st.info(f"üéÆ GPU d√©tect√©: {gpu_memory} GB VRAM")
else:
    st.warning("‚ö†Ô∏è Mode CPU: La g√©n√©ration sera plus lente")

# ---------- INTERFACE ----------
uploaded_file = st.file_uploader("üì∑ Image de d√©part (optionnel)", type=["png", "jpg", "jpeg"])
prompt = st.text_input("üìù Description de la vid√©o", value="A beautiful landscape with moving clouds")

col1, col2 = st.columns(2)
with col1:
    num_frames = st.slider("üéû Nombre de frames", 8, 24, 16)
with col2:
    resolution = st.selectbox("üé• R√©solution", ["512x512", "768x768", "1024x576"])

# ---------- G√âN√âRATION ----------
if st.button("üöÄ G√©n√©rer la vid√©o"):
    if not prompt.strip():
        st.error("‚ö†Ô∏è Veuillez entrer une description")
    else:
        progress = st.progress(0)
        status = st.empty()
        
        try:
            # Pr√©paration
            width, height = map(int, resolution.split("x"))
            input_image = None
            
            if uploaded_file:
                status.text("üì∑ Traitement image...")
                progress.progress(20)
                image = Image.open(uploaded_file)
                input_image = preprocess_image(image, (width, height))
            
            # G√©n√©ration
            status.text("üé¨ G√©n√©ration en cours...")
            progress.progress(40)
            
            frames = generate_frames(
                pipe, prompt, input_image, 
                num_frames, width, height, device
            )
            
            if frames and len(frames) > 0:
                progress.progress(80)
                status.text("üéû Cr√©ation vid√©o...")
                
                video_path = os.path.join(STATIC_DIR, "output.mp4")
                if create_video(frames, video_path):
                    progress.progress(100)
                    status.text("‚úÖ Termin√©!")
                    
                    st.success(f"üéâ Vid√©o g√©n√©r√©e: {len(frames)} frames")
                    st.video(video_path)
                    
                    with open(video_path, "rb") as f:
                        st.download_button(
                            "üì• T√©l√©charger",
                            f.read(),
                            "video.mp4",
                            "video/mp4"
                        )
                else:
                    st.error("‚ùå Erreur cr√©ation vid√©o")
            else:
                st.error("‚ùå Aucune frame g√©n√©r√©e")
                
        except Exception as e:
            st.error(f"üö® Erreur: {str(e)}")
        
        finally:
            if device == "cuda":
                torch.cuda.empty_cache()

# ---------- FOOTER ----------
st.markdown("---")
st.markdown("üé¨ **Vimeo AI Video Generator** - G√©n√©ration vid√©o IA locale", unsafe_allow_html=True)
